{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Final Exam Part B**\n",
        "\n",
        "Annelise Thorn (anth6800)"
      ],
      "metadata": {
        "id": "jcRhzNaLQOFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 1 (30 points): Designing a System"
      ],
      "metadata": {
        "id": "or2R0LBnQcbt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are tasked with designing a system to manage a large dataset of social media connections. The dataset comprises billions of users and their connections (friendship links) in a social network. Each user has an ID and maintains a list of their friends' IDs. Every user has defined hobbies, music, and movie preferences.\n",
        "\n",
        "**Design an efficient system that:**\n",
        "\n",
        "1. Store and manage this dataset considering the massive scale.\n",
        "2. Allows for quick retrieval of a user's friends or the friends of friends up to a certain level.\n",
        "3. Implements algorithms to suggest new friends to a user based on mutual friends or other relevant criteria (preferences of Hobbies, Music/Movies).\n",
        "4. Optimizes for space and time complexities in operations like adding new users, adding connections, and suggesting new connections.\n",
        "5. Define a name and a description for the classes and functions/methods you will implement. Add this list to your report.\n",
        "\n",
        "**Your solution should include:**(must be included in your report)\n",
        "\n",
        "1. A mind map with images and text for your approach encourages creativity and imagination in presentation. (take some ideas about mind maps here: https://mindmapsunleashed.com/10-really-cool-mind-mapping-examples-you-will-learn-fromLinks to an external site.).\n",
        "2. A general approach to your solution (4-5 paragraphs)\n",
        "3. A detailed explanation of the data structures you would use to store the user data and their connections, considering the scale of the dataset.\n",
        "4. Algorithms for efficiently retrieving friends or friends of friends within a limited degree of separation.\n",
        "5. Strategies for suggesting new connections to users.\n",
        "6. Analysis of the time and space complexities of your proposed solution, highlighting its efficiency and scalability.\n",
        "\n",
        "**Code/Jupyter Notebook:**\n",
        "\n",
        "A Python code with a small dataset including users (with hobbies/music/movie preferences), their friends, and a recommendation working algorithm.\n",
        "\n",
        "**Additional Notes:**\n",
        "\n",
        "* Consider scenarios where the dataset continues to increase.\n",
        "* Discuss any trade-offs, limitations, or challenges your proposed system might encounter.\n",
        "* Please ensure that you include any rational assumptions in your report.\n",
        "* Create one comprehensive Jupyter Notebook with the report and your working code.\n",
        "* If you need to upload any additional files with code, such as CSV, txt, jpg, or any other important files, please submit them to Canvas. Please make sure that you compile your solution with the uploaded files.\n",
        "\n",
        "**Grading:**\n",
        "\n",
        "* 15 points for the details of explanations/descriptions, algorithms used, and their complexity (Space and Time), classes, and methods (names and tasks).\n",
        "* 15 for the running Code in Python. (Jupyter Notebook)\n",
        "This question encompasses multiple aspects of data structures (like graphs, trees, hash maps), algorithms (graph traversal, recommendation algorithms), and problem-solving strategies (optimization, scalability). It challenges you to apply your understanding of these concepts and think critically about designing a system that addresses real-world issues at a large scale."
      ],
      "metadata": {
        "id": "u7hhCPXIRAlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "import random\n",
        "\n",
        "#adjacency list to represent friendship connections\n",
        "graph = {\n",
        "    \"user_id1\": {\"user_id2\": 1, \"user_id3\": 1, \"user_id4\": 1},\n",
        "    \"user_id2\": {\"user_id1\": 1, \"user_id3\": 1, \"user_id5\": 1, \"user_id9\": 1},\n",
        "    \"user_id3\": {\"user_id1\": 1, \"user_id2\": 1, \"user_id6\": 1, \"user_id8\": 1, \"user_id9\": 1},\n",
        "    \"user_id4\": {\"user_id1\": 1, \"user_id5\": 1, \"user_id8\": 1, \"user_id9\": 1},\n",
        "    \"user_id5\": {\"user_id4\": 1, \"user_id9\": 1},\n",
        "    \"user_id6\": {\"user_id3\": 1, \"user_id7\": 1, \"user_id9\": 1},\n",
        "    \"user_id7\": {\"user_id6\": 1, \"user_id8\": 1, \"user_id9\": 1},\n",
        "    \"user_id8\": {\"user_id3\": 1, \"user_id4\": 1, \"user_id7\": 1, \"user_id9\": 1},\n",
        "    \"user_id9\": {\"user_id2\": 1, \"user_id3\": 1, \"user_id4\": 1, \"user_id5\": 1, \"user_id6\": 1, \"user_id7\": 1, \"user_id8\": 1, \"user_id10\": 1},\n",
        "    \"user_id10\": {\"user_id9\": 1}\n",
        "}\n",
        "\n",
        "#hash maps to store users' hobbies, music, and movies preferences\n",
        "hobby_dictionary = {\"user_id1\": \"hiking\",\n",
        "                     \"user_id2\": \"running\",\n",
        "                     \"user_id3\": \"skiing\",\n",
        "                     \"user_id4\": \"climbing\",\n",
        "                     \"user_id5\": \"skiing\",\n",
        "                     \"user_id6\": \"climbing\",\n",
        "                     \"user_id7\": \"hiking\",\n",
        "                     \"user_id8\": \"hiking\",\n",
        "                     \"user_id9\": \"skiing\",\n",
        "                     \"user_id10\": \"running\"\n",
        "}\n",
        "\n",
        "music_dictionary = {\"user_id1\": \"pop\",\n",
        "                    \"user_id2\": \"pop\",\n",
        "                    \"user_id3\": \"country\",\n",
        "                    \"user_id4\": \"alternative\",\n",
        "                    \"user_id5\": \"rock\",\n",
        "                    \"user_id6\": \"pop\",\n",
        "                    \"user_id7\": \"rock\",\n",
        "                    \"user_id8\": \"country\",\n",
        "                    \"user_id9\": \"pop\",\n",
        "                    \"user_id10\": \"rock\"\n",
        "}\n",
        "\n",
        "movie_dictionary = {\"user_id1\": \"comedy\",\n",
        "                    \"user_id2\": \"drama\",\n",
        "                    \"user_id3\": \"comedy\",\n",
        "                    \"user_id4\": \"sci-fi\",\n",
        "                    \"user_id5\": \"sci-fi\",\n",
        "                    \"user_id6\": \"drama\",\n",
        "                    \"user_id7\": \"drama\",\n",
        "                    \"user_id8\": \"comedy\",\n",
        "                    \"user_id9\": \"sci-fi\",\n",
        "                    \"user_id10\": \"comedy\"\n",
        "}\n",
        "\n",
        "class Graph:\n",
        "    def __init__(self, graph: dict = {}, hobbies=None, music=None, movies=None):\n",
        "        #initialize the graph and preferences\n",
        "        self.graph = graph\n",
        "        self.hobbies = hobbies\n",
        "        self.music = music\n",
        "        self.movies = movies\n",
        "\n",
        "    def first_degree_connections(self, user_id):\n",
        "        #return keys of inner dictionary in graph\n",
        "        return list(self.graph.get(user_id, {}).keys())\n",
        "\n",
        "    def second_degree_connections(self, user_id):\n",
        "        #store unique second degree connections\n",
        "        second_degree_connections = set()\n",
        "        #store unique visited users\n",
        "        visited = set()\n",
        "        queue = deque([(user_id, 0)]) #depth 0\n",
        "\n",
        "        while queue:\n",
        "            #get the next user and depth from the queue\n",
        "            current_user, depth = queue.popleft()\n",
        "\n",
        "            #stop at second-degree connections\n",
        "            if depth > 1:\n",
        "                continue\n",
        "\n",
        "            if current_user not in visited:\n",
        "                #mark the user as visited\n",
        "                visited.add(current_user)\n",
        "\n",
        "                #loop through current user's friends\n",
        "                for friend in self.graph.get(current_user, {}):\n",
        "                    if friend not in visited:\n",
        "                        if depth == 1:\n",
        "                            second_degree_connections.add(friend)\n",
        "                        #add the friend to the queue with increased depth\n",
        "                        queue.append((friend, depth + 1))\n",
        "\n",
        "        return second_degree_connections\n",
        "\n",
        "    def third_degree_connections(self, user_id):\n",
        "        third_degree_connections = set()\n",
        "        visited = set()\n",
        "        queue = deque([(user_id, 0)]) #depth 0\n",
        "\n",
        "        while queue:\n",
        "            #get the next user and depth from the queue\n",
        "            current_user, depth = queue.popleft()\n",
        "\n",
        "            #stop at third-degree connections\n",
        "            if depth > 2:\n",
        "                continue\n",
        "\n",
        "            if current_user not in visited:\n",
        "                #mark the user as visited\n",
        "                visited.add(current_user)\n",
        "\n",
        "                #loop through current user's friends\n",
        "                for friend in self.graph.get(current_user, {}):\n",
        "                    if friend not in visited:\n",
        "                        if depth == 2:\n",
        "                            third_degree_connections.add(friend)\n",
        "                        #add the friend to the queue with increased depth\n",
        "                        queue.append((friend, depth + 1))\n",
        "\n",
        "        return third_degree_connections\n",
        "\n",
        "    def suggest_connections_based_on_interests(self):\n",
        "        suggested_graph = {}\n",
        "\n",
        "        #loop through each user\n",
        "        for user in self.graph.keys():\n",
        "            #initialize suggestions for the user\n",
        "            suggested_graph[user] = {}\n",
        "\n",
        "            #compare with every other user\n",
        "            for potential_friend in self.graph.keys():\n",
        "                if user == potential_friend or potential_friend in self.graph[user]:\n",
        "                    #skip self and already connected friends\n",
        "                    continue\n",
        "\n",
        "                #calculate similarity score based on interests\n",
        "                similarity_score = 0\n",
        "                if self.hobbies.get(user) == self.hobbies.get(potential_friend):\n",
        "                    similarity_score += 1\n",
        "                if self.music.get(user) == self.music.get(potential_friend):\n",
        "                    similarity_score += 1\n",
        "                if self.movies.get(user) == self.movies.get(potential_friend):\n",
        "                    similarity_score += 1\n",
        "\n",
        "                #only suggest if there is some similarity\n",
        "                if similarity_score > 0:\n",
        "                    suggested_graph[user][potential_friend] = similarity_score\n",
        "\n",
        "        return suggested_graph\n",
        "\n",
        "#create graph instances\n",
        "G = Graph(graph=graph, hobbies=hobby_dictionary, music=music_dictionary, movies=movie_dictionary)\n",
        "\n",
        "#test code:\n",
        "print(\"First degree connections:\", G.first_degree_connections(\"user_id10\"))\n",
        "print(\"Second degree connections:\", G.second_degree_connections(\"user_id10\"))\n",
        "print(\"Third degree connections:\", G.third_degree_connections(\"user_id10\"))\n",
        "\n",
        "suggested_graph = G.suggest_connections_based_on_interests()\n",
        "print(\"\\nSuggested Connections:\")\n",
        "for user, suggestions in suggested_graph.items():\n",
        "    print(f\"{user}: {suggestions}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grxgi9kf5IEh",
        "outputId": "e0518d38-a77b-4531-fcf2-0c669a7dfc69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First degree connections: ['user_id9']\n",
            "Second degree connections: {'user_id2', 'user_id5', 'user_id4', 'user_id7', 'user_id6', 'user_id8', 'user_id3'}\n",
            "Third degree connections: {'user_id5', 'user_id7', 'user_id6', 'user_id1', 'user_id8', 'user_id3'}\n",
            "\n",
            "Suggested Connections:\n",
            "user_id1: {'user_id6': 1, 'user_id7': 1, 'user_id8': 2, 'user_id9': 1, 'user_id10': 1}\n",
            "user_id2: {'user_id6': 2, 'user_id7': 1, 'user_id10': 1}\n",
            "user_id3: {'user_id5': 1, 'user_id10': 1}\n",
            "user_id4: {'user_id6': 1}\n",
            "user_id5: {'user_id3': 1, 'user_id7': 1, 'user_id10': 1}\n",
            "user_id6: {'user_id1': 1, 'user_id2': 2, 'user_id4': 1}\n",
            "user_id7: {'user_id1': 1, 'user_id2': 1, 'user_id5': 1, 'user_id10': 1}\n",
            "user_id8: {'user_id1': 2, 'user_id10': 1}\n",
            "user_id9: {'user_id1': 1}\n",
            "user_id10: {'user_id1': 1, 'user_id2': 1, 'user_id3': 1, 'user_id5': 1, 'user_id7': 1, 'user_id8': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 2 (25 points): Divide and Conquer Algorithm"
      ],
      "metadata": {
        "id": "r3n_FU6QRFGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this question, you will implement a Divide and Conquer algorithm for finding the maximum subarray sum (also known as Kadane's Algorithm) and compare it with a brute-force solution.\n",
        "\n",
        "\n",
        "\n",
        "**2.1) Implement both solutions and compare/analyze their time complexity.**\n",
        "\n",
        "> **A. Brute Force Approach: (10 points)**\n",
        "\n",
        "> Given an array of integers, A = [-2, 1, -3, 4, -1, 2, 1, -5, 4], find the  maximum sum of any contiguous subarray using the brute-force approach.\n",
        "\n",
        "> Describe the algorithm and show all steps to arrive at the correct result."
      ],
      "metadata": {
        "id": "84Ibko34RE62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = [-2, 1, -3, 4, -1, 2, 1, -5, 4]\n",
        "\n",
        "def brute_force(array):\n",
        "  max_sum = array[0]\n",
        "  #iterate over each element in the array to set the starting point of a subarray\n",
        "  for i in range(len(A)):\n",
        "    #iterate from the current starting point to the end of the array to form subarrays\n",
        "    for j in range(i, len(A)):\n",
        "      #calculate the sum of the current subarray from index i to j\n",
        "      curr = sum(A[i:j+1])\n",
        "      #update max_sum if the current subarray sum (curr) is greater than the previous max_sum\n",
        "      max_sum = max(max_sum, curr)\n",
        "  return max_sum\n",
        "\n",
        "print(brute_force(A))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAAREgbOgY4e",
        "outputId": "08dda1d1-49bd-4a32-cd0b-791aacca92a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Description of Algorithm:\n",
        "\n",
        "This algorithm iterates through all possible subarrays, calculating the sum of each subarray, and updating the max_sum whenever a higher sum is found. The time complexity is O(n^3)."
      ],
      "metadata": {
        "id": "iPHsptNwQWFV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **B. Divide and Conquer Approach: (10 points)**\n",
        "\n",
        "> Implement the Divide and Conquer approach to solve the Maximum Subarray Problem. Your solution should divide the array into two halves and recursively compute the maximum subarray sum in each half, as well as the maximum sum that crosses the middle."
      ],
      "metadata": {
        "id": "A4-twl2flf2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def divide_and_conquer(array, start, end):\n",
        "  #base case: if the subarray has only one element\n",
        "  if start == end:\n",
        "    #max sum is the single element itself\n",
        "    return array[start]\n",
        "\n",
        "  #calculate the midpoint\n",
        "  mid = (start + end) // 2\n",
        "  #recursively find the max subarray sum of the left half\n",
        "  left_max = divide_and_conquer(array, start, mid)\n",
        "  # recursively find the max subarray sum of the right half\n",
        "  right_max = divide_and_conquer(array, mid + 1, end)\n",
        "  #find the max sum that crosses the midpoint\n",
        "  cross_max = find_cross_max(array, start, mid, end)\n",
        "  #return the maximum of the three cases\n",
        "  return max(left_max, right_max, cross_max)\n",
        "\n",
        "def find_cross_max(array, start, mid, end):\n",
        "  #initialize left_sum and right_sum to negative infinity\n",
        "  left_sum = float('-inf')\n",
        "  right_sum = float('-inf')\n",
        "  for i in range(mid, start - 1, -1):\n",
        "    #calculate the sum of the left half\n",
        "    left_sum = max(left_sum, sum(array[i:mid+1]))\n",
        "  for j in range(mid + 1, end + 1):\n",
        "    #calculate the sum of the right half\n",
        "    right_sum = max(right_sum, sum(array[mid+1:j+1]))\n",
        "  #combine results\n",
        "  return left_sum + right_sum\n",
        "\n",
        "divide_and_conquer(A, 0, len(A)-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX_KL6hIlfU9",
        "outputId": "dd74ac47-2d89-4dcf-ef3b-bcd24a8819cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Description of Algorithm:\n",
        "\n",
        "This algorithm uses dynamic programming to recursively divide the array into smaller arrays, solve for the left and right halves, and the subarray that spans the midpoint. It then calculates the max_sum of seach of these and returns the highest value. The time complexity is O(n^2)."
      ],
      "metadata": {
        "id": "2KntCRMiSe-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2) Modify your Divide and Conquer algorithm (5 points)**\n",
        "\n",
        "Modify your Divide and Conquer algorithm to handle an additional constraint: Find the maximum subarray that must include a particular index i (where i is given as an input).\n",
        "\n",
        "Explain how the algorithm works with this new constraint and discuss the time complexity of the modified solution."
      ],
      "metadata": {
        "id": "cFqqnMp_li6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_oi = int(input(\"Enter the index of interest: \"))\n",
        "\n",
        "def divide_and_conquer(array, start, end, index_oi):\n",
        "  #base case: if the subarray has only one element\n",
        "  if start == end:\n",
        "    #ensure subarray includes index of interest\n",
        "    if start == i:\n",
        "      return array[start]\n",
        "    else:\n",
        "      return float('-inf')\n",
        "\n",
        "  #check index of index is within current range\n",
        "  if i < start or i > end:\n",
        "    #exclude subarrays that don't include index of interest\n",
        "    return float('-inf')\n",
        "\n",
        "  #calculate the midpoint\n",
        "  mid = (start + end) // 2\n",
        "  #recursively find the max subarray sum of the left half\n",
        "  left_max = divide_and_conquer(array, start, mid, index_oi)\n",
        "  # recursively find the max subarray sum of the right half\n",
        "  right_max = divide_and_conquer(array, mid + 1, end, index_oi)\n",
        "  #find the max sum that crosses the midpoint\n",
        "  cross_max = find_cross_max(array, start, mid, end)\n",
        "  #return the maximum of the three cases\n",
        "  return max(left_max, right_max, cross_max)\n",
        "\n",
        "def find_cross_max(array, start, mid, end):\n",
        "  #initialize left_sum and right_sum to negative infinity\n",
        "  left_sum = float('-inf')\n",
        "  right_sum = float('-inf')\n",
        "  for i in range(mid, start - 1, -1):\n",
        "    #calculate the sum of the left half\n",
        "    left_sum = max(left_sum, sum(array[i:mid+1]))\n",
        "  for j in range(mid + 1, end + 1):\n",
        "    #calculate the sum of the right half\n",
        "    right_sum = max(right_sum, sum(array[mid+1:j+1]))\n",
        "  #combine results\n",
        "  return left_sum + right_sum\n",
        "\n",
        "divide_and_conquer(A, 0, len(A)-1, index_oi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC-C1PAm81Ay",
        "outputId": "612e0c93-2ef4-4f6c-9640-2a561212c485"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the index of interest: 2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Description of Algorithm:\n",
        "\n",
        "This algorithm finds the max_sum of a subarray that includes a specific index of interest by recursively dividng the array into smaller subarrays, ensuring that the subarray being considered always includes the index of interest, and then calculates the max_sum of the left, right, and crossing subarrays. The time complexity is O(n*logn).\n"
      ],
      "metadata": {
        "id": "MJWjqX_RSWRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 3 (25 points): Dynamic Document Search Engine"
      ],
      "metadata": {
        "id": "tkdy4je1RNNf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario:**\n",
        "\n",
        "Imagine you are building the backend for a document search engine that allows users to search for specific terms in a set of documents. The system must be optimized for speed and memory efficiency, as it will need to handle millions of documents.\n",
        "\n",
        "**3.1 Document Representation: (10 points)**\n",
        "\n",
        "> Each document contains a set of words. A word can appear multiple times in a document.\n",
        "\n",
        "> Create a data structure that allows you to efficiently store documents, where a unique ID identifies each document, and each word is stored along with its frequency in the document."
      ],
      "metadata": {
        "id": "OmFKGto3RO1n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4qX0j_tQE72"
      },
      "outputs": [],
      "source": [
        "#example data structure- outer dictionary for document IDs and inner dictionary where key=word from document and value=word frequency\n",
        "documents = {\n",
        "    \"doc1\":{\"word1\":10, \"word2\":15, \"word3\":20},\n",
        "    \"doc2\":{\"word1\":10, \"word2\":15, \"word3\":20},\n",
        "    \"doc3\":{\"word1\":10, \"word2\":15, \"word3\":20},\n",
        "    \"doc4\":{\"word1\":15, \"word2\":20,}\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2 Search Functionality: (10 points)**\n",
        "\n",
        "> Implement a search function that can quickly return the documents that contain a given word. Additionally, return the frequency of the word within each document."
      ],
      "metadata": {
        "id": "vgiUyAMgpbUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search(word):\n",
        "  #initialize results dictionary to store document IDs and word frequencies\n",
        "  results = {}\n",
        "  #loop through each document in the 'documents' dictionary\n",
        "  for doc_id, doc in documents.items():\n",
        "    #check if the word of interest is in the doc\n",
        "    if word in doc:\n",
        "      #if found in the doc, add the doc ID as a key and the frequency of the word as the value in the results dict\n",
        "      results[doc_id] = doc[word]\n",
        "  return results\n",
        "\n",
        "search(\"word1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrbcW1lrpdTk",
        "outputId": "943e07d8-5a99-4f3a-eb73-8521a5df1406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'doc1': 10, 'doc2': 10, 'doc3': 10, 'doc4': 15}"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.3 Advanced Query Support: (5 points)**\n",
        "\n",
        "> Implement support for AND and OR queries, where users can search for documents containing multiple words.\n",
        "\n",
        "\n",
        "\n",
        "For example:\n",
        "\n",
        "> \"apple AND banana\" should return documents containing both \"apple\" and \"banana\".\n",
        "\n",
        "> \"apple OR banana\" should return documents containing either \"apple\" or \"banana\".\n",
        "\n",
        "\n",
        "**Hints:**\n",
        "\n",
        "* Efficiency Considerations: Consider breaking down the problem into two parts: storing the data and querying it.\n",
        "* Edge Cases: What happens if a word does not appear in any document? What if you query for words with typos or partial matches?"
      ],
      "metadata": {
        "id": "3xo6McpNpd2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def and_search(word1, word2):\n",
        "  #initialize results dictionary to store document IDs and word frequencies\n",
        "  results = {}\n",
        "  #loop through each document in the 'documents' dictionary\n",
        "  for doc_id, doc in documents.items():\n",
        "    #if both words are in the doc\n",
        "    if word1 in doc and word2 in doc:\n",
        "      #sum their frequencies\n",
        "      results[doc_id] = doc[word1] + doc[word2]\n",
        "  return results\n",
        "\n",
        "def or_search(word1, word2):\n",
        "  #initialize results dictionary to store document IDs and word frequencies\n",
        "  results = {}\n",
        "  #loop through each document in the 'documents' dictionary\n",
        "  for doc_id, doc in documents.items():\n",
        "    #if at least one of the words is in the doc\n",
        "    if word1 in doc or word2 in doc:\n",
        "      #sum their frequencies\n",
        "      results[doc_id] = doc.get(word1, 0) + doc.get(word2, 0)\n",
        "  return results\n",
        "\n",
        "print(\"AND:\", and_search(\"word2\", \"word3\"))\n",
        "print(\"OR:\", or_search(\"word2\", \"word3\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_n_8uu7peTO",
        "outputId": "a03c3483-f8c9-44e0-e08e-97974b03fcfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND: {'doc1': 35, 'doc2': 35, 'doc3': 35}\n",
            "OR: {'doc1': 35, 'doc2': 35, 'doc3': 35, 'doc4': 20}\n"
          ]
        }
      ]
    }
  ]
}